# Observability stack for Angzarr
# Deploys Grafana + Tempo + Prometheus + Loki + OTel Collector + Promtail
#
# Data flow:
#   Sidecars --OTLP--> OTel Collector ---> Tempo       (traces)
#                                     ---> Prometheus  (metrics via remote write)
#                                     ---> Loki        (logs, structured via OTLP)
#   Promtail (DaemonSet) ---> Loki (stdout/stderr from business containers)
#   Grafana reads from all three backends.

# Angzarr dashboards
dashboards:
  enabled: true
  files:
    command-pipeline: {}
    event-bus: {}
    orchestration: {}
    service-graph: {}  # OTel service graph via Tempo (replaces old topology)

# Default resource configuration
resources:
  requests:
    memory: "128Mi"
    cpu: "50m"
  limits:
    memory: "512Mi"
    cpu: "500m"

# --- Tempo: Distributed tracing backend ---
tempo:
  enabled: true
  tempo:
    storage:
      trace:
        backend: local
        local:
          path: /var/tempo/traces
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: "0.0.0.0:4317"
  resources:
    requests:
      memory: "128Mi"
      cpu: "50m"
    limits:
      memory: "512Mi"
      cpu: "500m"

# --- Prometheus: Metrics backend ---
prometheus:
  enabled: true
  server:
    extraFlags:
      - "web.enable-remote-write-receiver"
    retention: "24h"
    persistentVolume:
      enabled: false
    resources:
      requests:
        memory: "128Mi"
        cpu: "50m"
      limits:
        memory: "512Mi"
        cpu: "500m"
  alertmanager:
    enabled: false
  kube-state-metrics:
    enabled: false
  prometheus-node-exporter:
    enabled: false
  prometheus-pushgateway:
    enabled: false

# --- Loki: Log aggregation backend ---
loki:
  enabled: true
  deploymentMode: SingleBinary
  loki:
    auth_enabled: false
    commonConfig:
      replication_factor: 1
    storage:
      type: filesystem
    schemaConfig:
      configs:
        - from: "2024-01-01"
          store: tsdb
          object_store: filesystem
          schema: v13
          index:
            prefix: index_
            period: 24h
  singleBinary:
    replicas: 1
    resources:
      requests:
        memory: "128Mi"
        cpu: "50m"
      limits:
        memory: "512Mi"
        cpu: "500m"
  backend:
    replicas: 0
  read:
    replicas: 0
  write:
    replicas: 0
  gateway:
    enabled: false

# --- Promtail: DaemonSet log collector ---
# Scrapes container logs and ships to Loki.
# Drops logs from "angzarr" containers to avoid duplicating OTLP-exported logs.
promtail:
  enabled: true
  config:
    clients:
      - url: http://{{ .Release.Name }}-loki:3100/loki/api/v1/push
    snippets:
      pipelineStages:
        - match:
            selector: '{container="angzarr"}'
            action: drop
            drop_counter_reason: angzarr_sidecar_otlp_duplicate
  resources:
    requests:
      memory: "64Mi"
      cpu: "25m"
    limits:
      memory: "128Mi"
      cpu: "100m"

# --- OpenTelemetry Collector: OTLP receiver, fans out to backends ---
opentelemetry-collector:
  enabled: true
  mode: deployment
  image:
    repository: otel/opentelemetry-collector-contrib
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: "0.0.0.0:4317"
          http:
            endpoint: "0.0.0.0:4318"
    processors:
      batch:
        timeout: 5s
        send_batch_size: 1024
      memory_limiter:
        check_interval: 1s
        limit_percentage: 80
        spike_limit_percentage: 25
    # Connectors bridge pipelines - servicegraph consumes traces, emits metrics
    connectors:
      servicegraph:
        latency_histogram_buckets: [1ms, 2ms, 5ms, 10ms, 25ms, 50ms, 100ms, 250ms, 500ms, 1s, 2s, 5s]
        dimensions:
          - service.namespace
        store:
          ttl: 2s
          max_items: 1000
    exporters:
      # Traces -> Tempo via OTLP gRPC
      otlp:
        endpoint: "{{ .Release.Name }}-tempo:4317"
        tls:
          insecure: true
      # Metrics -> Prometheus via remote write
      prometheusremotewrite:
        endpoint: "http://{{ .Release.Name }}-prometheus-server:80/api/v1/write"
        tls:
          insecure: true
      # Logs -> Loki via OTLP HTTP
      otlphttp/loki:
        endpoint: "http://{{ .Release.Name }}-loki:3100/otlp"
        tls:
          insecure: true
      debug:
        verbosity: basic
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [otlp, servicegraph]  # Also feed servicegraph connector
        metrics:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [prometheusremotewrite]
        # Service graph metrics pipeline - connector output -> Prometheus
        metrics/servicegraph:
          receivers: [servicegraph]
          processors: [memory_limiter, batch]
          exporters: [prometheusremotewrite]
        logs:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [otlphttp/loki]
  service:
    type: NodePort
  ports:
    otlp:
      enabled: true
      containerPort: 4317
      servicePort: 4317
      hostPort: 4317
      protocol: TCP
      nodePort: 30417
    otlp-http:
      enabled: true
      containerPort: 4318
      servicePort: 4318
      protocol: TCP
  resources:
    requests:
      memory: "128Mi"
      cpu: "50m"
    limits:
      memory: "512Mi"
      cpu: "500m"

# --- Grafana: Visualization ---
grafana:
  enabled: true
  adminUser: admin
  adminPassword: angzarr
  service:
    type: NodePort
    nodePort: 30300
  plugins: []
    # Infinity plugin removed - topology now via OTel service graph
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      folder: /var/lib/grafana/dashboards/angzarr
      provider:
        name: angzarr
        orgId: 1
        folder: Angzarr
        disableDeletion: false
        allowUiUpdates: true
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Tempo
          type: tempo
          access: proxy
          url: http://{{ .Release.Name }}-tempo:3100
          uid: tempo
          isDefault: false
          jsonData:
            tracesToLogsV2:
              datasourceUid: loki
              filterByTraceID: true
            tracesToMetrics:
              datasourceUid: prometheus
            # Service graph from OTel servicegraph connector metrics
            serviceMap:
              datasourceUid: prometheus
        - name: Prometheus
          type: prometheus
          access: proxy
          url: http://{{ .Release.Name }}-prometheus-server:80
          isDefault: true
          uid: prometheus
        - name: Loki
          type: loki
          access: proxy
          url: http://{{ .Release.Name }}-loki:3100
          uid: loki
          jsonData:
            derivedFields:
              - datasourceUid: tempo
                matcherRegex: "trace_id=(\\w+)"
                name: TraceID
                url: "$${__value.raw}"
  resources:
    requests:
      memory: "128Mi"
      cpu: "50m"
    limits:
      memory: "512Mi"
      cpu: "500m"
